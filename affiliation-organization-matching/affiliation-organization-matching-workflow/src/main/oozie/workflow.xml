<workflow-app xmlns="uri:oozie:workflow:0.4" name="affiliation-organization-matching-wf">
    <parameters>
        <property>
            <name>DFS_SOCKET_CLIENT_TIMEOUT</name>
            <value>120000</value>
        </property>
        <property>
            <name>MAPRED_TASK_TIMEOUT</name>
            <value>3600000</value>
        </property>
        <property>
            <name>POOL_NAME</name>
            <value>default</value>
        </property>
        <property>
            <name>INITIAL_MAX_DOCS_SET_SIZE</name>
            <value>1000</value>
        </property>
        <property>
            <name>MAX_DOCS_SET_SIZE_INC</name>
            <value>200</value>
        </property>
        <property>
            <name>MAX_SPLIT_LEVEL</name>
            <value>10</value>
        </property>
        <property>
            <name>MAPRED_REDUCE_TASKS</name>
            <value>16</value>
        </property>
        <property>
            <name>SPARK_EXECUTOR_MEMORY</name>
            <value>10G</value>
        </property>
        <property>
            <name>SPARK_DRIVER_MEMORY</name>
            <value>60G</value>
        </property>
         <property>
            <name>SPARK_NUM_EXECUTORS</name>
            <value>60</value>
        </property>
         <property>
            <name>SPARK_ADDITIONAL_OPTS</name>
            <value> </value>
        </property>
    </parameters>
 <start to="affiliation-organization-matching" />
    <action name="affiliation-organization-matching">
          <spark xmlns="uri:oozie:spark-action:0.1">
            <job-tracker>${jobTracker}</job-tracker>
            <name-node>${nameNode}</name-node>
            <prepare>
               <delete path="${outputSeqFile}"/>
            </prepare>
           <master>yarn-cluster</master>
            <name>Affiliation matching</name>
            <class>pl.edu.icm.coansys.matching.organization.DoMatching</class>
            <jar>${comacWfPath}/lib/affiliation-organization-matching-impl-1.10-SNAPSHOT.jar</jar>
            <spark-opts>--executor-memory ${SPARK_EXECUTOR_MEMORY} --driver-memory ${SPARK_DRIVER_MEMORY} --num-executors ${SPARK_NUM_EXECUTORS} ${SPARK_ADDITIONAL_OPTS}</spark-opts>
            <arg>${organizationsInputSeqFile}</arg>
            <arg>${documentsInputSeqFile}</arg>
            <arg>${outputSeqFile}</arg>
        </spark>
		<ok to="finalize" />
		<error to="finalize-error" />
	</action>   
	<kill name="finalize-error">
		<message>Workflow failed</message>
	</kill>
	<end name="finalize" />
</workflow-app>
