/*
 * This file is part of CoAnSys project.
 * Copyright (c) 20012-2013 ICM-UW
 * 
 * CoAnSys is free software: you can redistribute it and/or modify
 * it under the terms of the GNU Affero General Public License as published by
 * the Free Software Foundation, either version 3 of the License, or
 * (at your option) any later version.

 * CoAnSys is distributed in the hope that it will be useful,
 * but WITHOUT ANY WARRANTY; without even the implied warranty of
 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
 * GNU Affero General Public License for more details.
 * 
 * You should have received a copy of the GNU Affero General Public License
 * along with CoAnSys. If not, see <http://www.gnu.org/licenses/>.
 */

package pl.edu.icm.coansys.disambiguation.author.pig;

import java.io.IOException;
import java.util.ArrayList;
import java.util.Arrays;
import java.util.HashMap;
import java.util.Iterator;
import java.util.LinkedList;
import java.util.List;
import java.util.Map;

import org.apache.pig.EvalFunc;
import org.apache.pig.data.DataBag;
import org.apache.pig.data.DefaultDataBag;
import org.apache.pig.data.Tuple;
import org.apache.pig.data.TupleFactory;
import org.slf4j.LoggerFactory;

import pl.edu.icm.coansys.commons.java.StackTraceExtractor;
import pl.edu.icm.coansys.disambiguation.author.benchmark.Timer;
import pl.edu.icm.coansys.disambiguation.author.features.disambiguators.DisambiguatorFactory;

import pl.edu.icm.coansys.disambiguation.clustering.strategies.SingleLinkageHACStrategy_OnlyMax;
import pl.edu.icm.coansys.disambiguation.features.Disambiguator;
import pl.edu.icm.coansys.disambiguation.features.FeatureInfo;
import pl.edu.icm.coansys.disambiguation.idgenerators.IdGenerator;
import pl.edu.icm.coansys.disambiguation.idgenerators.UuIdGenerator;

public class ExhaustiveAND extends EvalFunc<DataBag> {

	private float threshold;

	private static final float NOT_CALCULATED = Float.NEGATIVE_INFINITY;	
	private PigDisambiguator[] features;
	private FeatureInfo[] featureInfos;
	private float sim[][];
    private static final org.slf4j.Logger logger = LoggerFactory.getLogger(ExhaustiveAND.class);
    //benchmark 
    private Timer timer;
    private int calculatedSimCounter; //using for statistics generated by timer
    private int timerPlayId = 0;

	public ExhaustiveAND(String threshold, String featureDescription){
		this.threshold = Float.parseFloat(threshold);
		
		List<FeatureInfo> FIwithEmpties 
			= FeatureInfo.parseFeatureInfoString(featureDescription);
		List<FeatureInfo> FIFinall = new LinkedList<FeatureInfo>();
		List<PigDisambiguator> FeaturesFinall = new LinkedList<PigDisambiguator>();
		
        DisambiguatorFactory ff = new DisambiguatorFactory();
        Disambiguator d;
        
        //separate features which are fully described and able to use
        for ( FeatureInfo fi : FIwithEmpties ){
        	if ( fi.getDisambiguatorName().equals("") ) continue;
        	if ( fi.getFeatureExtractorName().equals("") ) continue;
        	d = ff.create(fi);
        	if ( d == null ) continue;
        	FIFinall.add( fi );
        	FeaturesFinall.add( new PigDisambiguator( d ) );
        }
        
		this.featureInfos = FIFinall.toArray( new FeatureInfo[ FIFinall.size() ] );
        this.features = 
        		FeaturesFinall.toArray( new PigDisambiguator[ FIFinall.size() ] );
        
        timer = new Timer("logs/exhaustive.stat");
		(new Thread( timer )).start();
        timer.addMonit("id","contribs","clusters","calculated sims","time");
        timer.addMonit("S:", "=suma(B3:B1000000)", "=suma(C3:C1000000)", "=suma(D3:D1000000)","=suma(E3:E1000000)");
	}

	@SuppressWarnings("unchecked")
	@Override
	public DataBag exec( Tuple input ) throws IOException {

		if ( input == null || input.size() == 0 ) return null;
		try{
			
			DataBag contribs = (DataBag) input.get(0);  
			
			if ( contribs == null || contribs.size() == 0 ) return null;
			
			//start benchmark
			timer.play();
			calculatedSimCounter = 0;
			timerPlayId++;
			
			Iterator<Tuple> it = contribs.iterator();	

			List< Map<String,Object> > contribsT = new LinkedList< Map<String,Object> > ();
			List< String > contribsId = new LinkedList<String>();


			while ( it.hasNext() ) { 
				Tuple t = it.next();
				contribsId.add( (String) t.get(0) ); //biore contrId z Tupla
				contribsT.add( (Map<String, Object>) t.get(3) );
			}

			sim = new float[ contribsT.size() ][];
			for ( int i = 1; i < contribsT.size(); i++ ) {
				sim[i] = new float[i];
				for ( int j = 0; j < i; j++ )
					sim[i][j] = NOT_CALCULATED;
			}

			//if we got sim values to init
			if ( input.size() == 2 ) {
				//taking bag with calculated similarities
				DataBag similarities = (DataBag) input.get(1);  
				it = similarities.iterator();	
				//iterating through bag, dropping bag to Tuple array
				while ( it.hasNext() ) { 
					Tuple t = it.next();
					calculatedSimCounter++;
					
					int idX = (Integer) t.get(0);
					int idY = (Integer) t.get(1);
					float simValue = (Float) t.get(2);

					try {
						sim[ idX ][ idY ] = simValue;

					} catch ( java.lang.ArrayIndexOutOfBoundsException e ) {

						String m = "Out of bounds during sim init by values from input: " + "idX: " + idX + ", idY: " + idY + ", sim.length: " + sim.length +
								", contrib number: " + contribsT.size();

						if ( sim.length > idX )
							m += ", sim[idX].length: " + sim[idX].length;

						m+= "\n" + "Tuple debug: " + t.toString();

						throw new Exception(m, e);
					}
				}
			}

			calculateAffinity ( contribsT );
			
			// clusterAssociations[ index_kontrybutora ] = associated cluster id
	        int[] clusterAssociations = new SingleLinkageHACStrategy_OnlyMax().clusterize( sim );

	        Map<Integer,List<String>> clusterMap = splitIntoMap( clusterAssociations, contribsId );
	        
	        //stopping timer for current play (not thread)
	        //this action will add some information to timer monit
	        timer.stop( timerPlayId, contribs.size(), clusterMap.size(), calculatedSimCounter );
	        
	        return createResultingTuples( clusterMap );
		}catch(Exception e){
			// Throwing an exception would cause the task to fail.
			logger.error("Caught exception processing input row:\n" + StackTraceExtractor.getStackTrace(e));
                        return null;
		}
	}

	private void calculateAffinity( List< Map<String,Object> > contribsT ) throws Exception {

		for ( int i = 1; i < contribsT.size(); i++ ) {
			for ( int j = 0; j < i; j++ ) {

				//if sim value is already calculated, we do not need to calculate one more time
				if( sim[i][j] != NOT_CALCULATED ) continue;
				sim[i][j] = threshold;

				for ( int d = 0; d < features.length; d++ ){
					//Taking features from each keys (name of extractor = feature name)
					//In contribsT.get(i) there is map we need.
					//From this map (collection of i'th contributor's features)
					//we take Bag with value of given feature.
					//Here we have sure that following Object = DateBag.
					Object oA = contribsT.get(i).get( featureInfos[d].getFeatureExtractorName() );
					Object oB = contribsT.get(j).get( featureInfos[d].getFeatureExtractorName() );
					
					if ( oA == null || oB == null ) continue;
					
					double partial = features[d].calculateAffinity( oA, oB );
					
					if ( featureInfos[d].getMaxValue() == 0 ) continue;
					partial = partial / featureInfos[d].getMaxValue() 
							* featureInfos[d].getWeight();
					sim[i][j] += partial;

        			if ( sim[i][j] >= 0 ) break;
				}
			}
		}
	}

	protected Map<Integer, List<String>> splitIntoMap(int[] clusterAssociation, List<String> authorIds) {

		//putting contrib id under cluster id (clusetAssociation)
		Map<Integer, List<String>> clusterMap = new HashMap<Integer, List<String>>();
		//TODO: map to list like in aproximateAND

        for (int i = 0; i < clusterAssociation.length; i++) {
            addToMap(clusterMap, clusterAssociation[i], authorIds.get(i));
        }
		return clusterMap;
	}

	protected <K, V> void addToMap(Map<Integer, List<String>> clusters, int clusterAssociation, String string) {

		//checking if the id cluster id has not been in map so far
		List<String> values = clusters.get(clusterAssociation);
        if (values == null) {
            values = new ArrayList<String>();
            values.add(string);
            clusters.put(clusterAssociation, values);
        }else{
        	//adding if not
        	values.add(string);
        }
    }

	protected DataBag createResultingTuples( Map<Integer, List<String>> clusterMap ) {
    	IdGenerator idgenerator = new UuIdGenerator();

    	DataBag ret = new DefaultDataBag();
        for (Map.Entry<Integer, List<String>> o : clusterMap.entrySet()) {
        	String clusterId = idgenerator.genetareId(o.getValue());

        	DataBag contribs = new DefaultDataBag();
        	for(String s : o.getValue()){
        		contribs.add(TupleFactory.getInstance().newTuple(s));
        	}

        	Object[] to = new Object[]{clusterId,contribs};
	        ret.add(TupleFactory.getInstance().newTuple(Arrays.asList(to)));
        }
		return ret;
	}
}
